recode = T, #adds labels for variables, optional
variables_filter = list(AGEP = 18:65) #optional filter for Age in 18:65, optional
)
head(pums_tx)
readr::write_csv(pums_tx,
file  = "pums_tx_2019.csv")
View(v19_Profile)
head(sa_acs)
knitr::opts_chunk$set(echo = TRUE)
library(tidycensus, quietly = T)
library(tidyverse, quietly = T)
library(sf, quietly = T)
library(tmap, quietly = T)
v19_Profile <- load_variables(year = 2019 ,
dataset = "acs5/profile",
cache = TRUE) #data profile tables
v19_Profile[grep(x = v19_Profile$label, "Median household"),
c("name", "label")]
v19_detailed <- load_variables(year = 2019 ,
dataset = "acs5")# detail tables
knitr::kable(v19_detailed[grep(x = v19_detailed$label, "Median household"),
c("name", "label")], format = "html")
sa_acs<-get_acs(geography = "tract", #level of geography requested
state="TX", #can use state FIPS codes as well e.g. 48
county = "029", #County FIPS codes are safer
year = 2019,
variables=c( "DP03_0062E") ,
geometry = T, #merge estimates to Census geographies
output = "wide")
head(sa_acs)
sa_acs<-sa_acs%>%
# mutate( medhhinc=DP03_0062E,
#         medhhinc_moe = DP03_0062M) %>%
select(GEOID, NAME, medhhinc=DP03_0062E, medhhinc_moe= DP03_0062M )%>%
filter(complete.cases(medhhinc))
#take a peek at the first few lines of data
head(sa_acs)
tmap_mode("plot")
library(tmap) #need to install on your system
sa_acs%>%
tm_shape()+
tm_polygons("medhhinc",
title="Median Income",
palette="Blues",
style="quantile", n=5 )+
tm_format("World",
title="San Antonio Median Household Income Estimates\n Quantile Breaks, 2019",
legend.outside=T)+
tm_scale_bar()+
tm_compass()
tmap_save(filename = "SA_Income.png")
tmap_mode("view")
sa_acs%>%
tm_shape()+
tm_polygons("medhhinc",
alpha = .75,
title="Median Income",
palette="Blues",
style="quantile", n=5 )
person_2019 <- pums_variables%>%
filter(year == 2019,
survey == "acs5",
level == "person")
knitr::kable(head(person_2019, n = 20),
align = 'c',
format = "html")
pums_tx <- get_pums(year = 2019,
state = c("TX"),  #list of states, FIPS codes also work
survey = "acs5", # survey you are wanting
variables =c("ST","PUMA", "PWGTP", "AGEP", "SCHL", "SEX", "WAGP", "HISP", "RAC1P", "FOD1P"),
recode = T, #adds labels for variables, optional
variables_filter = list(AGEP = 18:65) #optional filter for Age in 18:65, optional
)
head(pums_tx)
readr::write_csv(pums_tx,
file  = "pums_tx_2019.csv")
knitr::opts_chunk$set(echo = TRUE)
x1<-c(1,5, 1)
x2<-c(5, 1, 2)
dist( rbind(x1, x2), method = "euclidean")
x1<-c(1,5, 1)
x2<-c(1, 2, 2)
x3<-c(8,7,10)
dist( rbind(x1, x2, x3), method = "euclidean")
library(readr)
prb<-read_csv(file = url("https://github.com/coreysparks/data/blob/master/PRB2008_All.csv?raw=true"))
names(prb)<-tolower(names(prb))
library(dplyr)
prb<-prb%>%
# mutate(africa=ifelse(continent=="Africa", 1, 0))%>%
mutate(lngdp=log(gnippppercapitausdollars))%>%
select(continent, country, lngdp, tfr, percpoplt15, e0total, percurban)%>%
filter(complete.cases(.))
knitr::kable(head(prb))
library(caret)
set.seed(1115)
train<- createDataPartition(y = prb$lngdp, p = .80, list=F)
prbtrain<-prb[train,]
prbtest<-prb[-train,]
dmat<-dist(prbtrain, method="euclidean")
library(scorecard)
library(factoextra)
library(class)
library(RColorBrewer)
hc1<-hclust(d= dmat, method="single")
fviz_dend(hc1, k=5, k_colors =brewer.pal(n=5, name="Accent"),
color_labels_by_k = TRUE, ggtheme = theme_minimal())
groups<-cutree(hc1, k=5)
table(groups)
hc2<-hclust(d= dmat,
method="ward.D")
fviz_dend(hc2, k=4,
k_colors = brewer.pal(n=5, name="Accent"),
color_labels_by_k = TRUE,
ggtheme = theme_minimal())
groups<-cutree(hc2, k=5)
table(groups)
prbtrain$group1<-factor(cutree(hc2, k=4))
prbtrain%>%
ggplot(aes(x=lngdp, y=tfr, pch=group1, color=group1))+
geom_point()
prbtrain%>%
ggplot(aes(x=percpoplt15, y=tfr, pch=group1, color=group1))+
geom_point()
dmat<-dist(scale(prbtrain), method="euclidean")
names(prbtrain)
train<- createDataPartition(y = prb$e0total, p = .80, list=F)
prbtrain<-prb[train,]
prbtest<-prb[-train,]
dmat<-dist(scale(prbtrain[, 3:8]), method="euclidean")
head(prbtrain[, 3:8])
dmat<-dist(scale(prbtrain[, 3:7]), method="euclidean")
library(scorecard)
library(factoextra)
library(class)
library(RColorBrewer)
hc1<-hclust(d= dmat, method="single")
fviz_dend(hc1, k=5, k_colors =brewer.pal(n=5, name="Accent"),
color_labels_by_k = TRUE, ggtheme = theme_minimal())
groups<-cutree(hc1, k=5)
table(groups)
hc2<-hclust(d= dmat,
method="ward.D")
fviz_dend(hc2, k=4,
k_colors = brewer.pal(n=5, name="Accent"),
color_labels_by_k = TRUE,
ggtheme = theme_minimal())
groups<-cutree(hc2, k=5)
table(groups)
prbtrain$group1<-factor(cutree(hc2, k=4))
prbtrain%>%
ggplot(aes(x=percpoplt15, y=tfr, pch=group1, color=group1))+
geom_point()
prbtrain%>%
ggplot(aes(x=e0total, y=tfr, pch=group1, color=group1))+
geom_point()
km<-kmeans(x = scale(prbtrain[, 3:7]),
center = 3,
nstart = 20)
km
library(ClusterR)
km2<-KMeans_rcpp(data=scale(prbtrain[, 3:7]), cluster=4, num_init = 10)
prbtrain$cluster<-as.factor(km2$cluster)
prbtrain%>%
ggplot(aes(x=lngdp, y=tfr, group=cluster, color=cluster))+
geom_point( cex=2)
ss<-NULL
for(i in 1:10){
km<-kmeans(x=scale(prbtrain[, 3:7]),
nstart = 10,
centers = i)
ss[i]<-km$withinss
}
plot(x=1:10, y=ss, type = "l")
fviz_nbclust(scale(prbtrain[, c(-1:-2)]), kmeans, nstart=20, method="wss")
fviz_nbclust(scale(prbtrain[, 3:7]), kmeans, nstart=20, method="wss")
kmeans_fancy <- kmeans(scale(prbtrain[, 3:7]),3, nstart = 100)
fviz_cluster(kmeans_fancy,
data = scale(prbtrain[, 3:7]),
geom = c("point"),
ellipse.type = "convex")
gap_stat <- clusGap(scale(prbtrain[, 3:7]),
FUN = kmeans,
nstart = 30,
K.max = 10, B = 100)
library(cluster)
gap_stat <- clusGap(scale(prbtrain[, 3:7]),
FUN = kmeans,
nstart = 30,
K.max = 10, B = 100)
fviz_gap_stat(gap_stat) +
theme_minimal() +
ggtitle("fviz_gap_stat: Gap Statistic")
fviz_nbclust(scale(prbtrain[, 3:7]),FUNcluster =  kmeans,
method = "silhouette", k.max = 10) +
theme_minimal() +
ggtitle("The Silhouette Plot")
prbtest$cluster<-as.factor(predict_KMeans(data=scale(prbtest[, 3:7]),
CENTROIDS = km2$centroids))
prbtest%>%
ggplot(aes(x=lngdp, y=tfr, group=cluster, color=cluster))+
geom_point(cex=4, pch="x")+
geom_point(data=prbtrain,
aes(x=lngdp, y=tfr, group=cluster, color=cluster))
prbtest%>%
ggplot(aes(x=e0total, y=tfr, group=cluster, color=cluster))+
geom_point(cex=4, pch="x")+
geom_point(data=prbtrain,
aes(x=e0total, y=tfr, group=cluster, color=cluster))
library(factoextra)
km.res <- eclust(scale(prbtrain[, 3:7]),
FUNcluster =  "kmeans",
k = 3,
nstart = 25,
graph = FALSE)
fviz_cluster(km.res,  ellipse.type = "norm", ellipse.level = 0.68)
fviz_silhouette(km.res)
res.hc <- eclust(scale(prbtrain[, 3:7]), "hclust", k = 4,
method = "ward.D2", graph = FALSE)
head(res.hc$cluster, 15)
fviz_dend(res.hc, rect = TRUE, show_labels = TRUE, cex = 0.5)
res.hc <- eclust(scale(prbtrain[, 3:7]), "hclust", k = 4,
method = "ward.D2", graph = FALSE)
grp <- res.hc$cluster
clus.centers <- aggregate(prbtrain, list(grp), mean)
clus.centers
prbtrain%>%
group_by(cluster)%>%
summarise_all(lngdp, e0total, percpoplt15, tfr)
prbtrain%>%
group_by(cluster)%>%
summarise_all(lngdp, e0total, percpoplt15, tfr, .funs = "mean")
names(prbtrain)
prbtrain%>%
group_by(cluster)%>%
summarise_all(vars(lngdp, e0total, percpoplt15, tfr), .funs = "mean")
prbtrain%>%
group_by(cluster)%>%
summarise_all(vars(lngdp, e0total, percpoplt15, tfr), .funs = "mean", na.rm=T)
prbtrain%>%
group_by(cluster)%>%
summarise_at(vars(lngdp, e0total, percpoplt15, tfr),mean, na.rm=T)
knitr::opts_chunk$set(echo = TRUE)
library(ipeds)
library(tidyverse)
library(FactoMineR)
library(factoextra)
library(here)
hd = readxl::read_xlsx(paste(here(), "/OneDrive - University of Texas at San Antonio/excelencia_course/IPEDS/IPEDS_2017-18_Final/HD2017.xlsx", sep=""))
knitr::opts_chunk$set(echo = TRUE)
library(ipeds)
library(tidyverse)
library(FactoMineR)
library(factoextra)
library(here)
hd = readxl::read_xlsx(paste(here(), "/excelencia_course/IPEDS/IPEDS_2017-18_Final/HD2017.xlsx", sep=""))
hd = readxl::read_xlsx(paste(here(), "/IPEDS/IPEDS_2017-18_Final/HD2017.xlsx", sep=""))
ic = readxl::read_xlsx(paste(here(), "/IPEDS/IPEDS_2017-18_Final/IC2017.xlsx", sep=""))
icay= readxl::read_xlsx(paste(here(), "/IPEDS/IPEDS_2017-18_Final/IC2017_AY.xlsx", sep=""))
mdat<- left_join(hd, ic, by ="UNITID")
mdat<-left_join(mdat, icay, by = "UNITID")
mdat<-mdat%>%
filter(CYACTIVE==1, HDEGOFR1>0, OPENADMP>0)%>%
select(UNITID, SECTOR, ICLEVEL, HLOFFER, GROFFER, HDEGOFR1, HBCU, LOCALE, INSTSIZE, OPENADMP)%>%
filter(complete.cases(.))
names(mdat)<- tolower(names(mdat))
mat <- model.matrix(~sector+iclevel+hloffer+groffer+hdegofr1+hbcu+locale+instsize+openadmp-1, data=mdat)
pcs <- prcomp(mat, retx=T, scale. = T, center = T)
ss <- NA
for (i in 1:10){
ss[i]<- kmeans(mat, centers = i, nstart=20)$withinss
}
plot(ss, type = "l")
out<- kmeans(mat, centers = 4, nstart=20)
out
out$centers
mat <- model.matrix(~factor(sector)+factor(iclevel)+factor(hloffer)+factor(groffer)+factor(hdegofr1)+factor(hbcu)+factor(locale)+factor(instsize)+factor(openadmp)-1, data=mdat)
pcs <- prcomp(mat, retx=T, scale. = T, center = T)
ss <- NA
for (i in 1:10){
ss[i]<- kmeans(mat, centers = i, nstart=20)$withinss
}
plot(ss, type = "l")
out<- kmeans(mat, centers = 6, nstart=20)
out$centers
out<- kmeans(mat, centers = 6, nstart=20)
out$centers
mdat$cluster <- out$cluster
library(ggplot2)
mdat%>%
group_by(cluster, sector, .drop=F )%>%
summarise(n = n()) %>%
mutate(freq = n / sum(n))%>%
ggplot()+
geom_bar(aes(x=cluster, y=freq, group=sector, fill=factor(sector) ),position="dodge", stat="identity")
library(ggplot2)
mdat%>%
group_by(cluster, sector, .drop=F )%>%
summarise(n = n()) %>%
mutate(freq = n / sum(n))%>%
ggplot()+
geom_bar(aes(x=cluster, y=freq, group=sector, fill=factor(sector) ),
position="dodge",
stat="identity")
mdat%>%
group_by(cluster, openadmp, .drop=F )%>%
summarise(n = n()) %>%
mutate(freq = n / sum(n))%>%
ggplot()+
geom_bar(aes(x=cluster, y=freq, group=sector, fill=factor(sector) ),
position="dodge",
stat="identity")
knitr::opts_chunk$set(echo = TRUE)
library(ipeds)
library(tidyverse)
library(FactoMineR)
library(factoextra)
library(here)
hd = readxl::read_xlsx(paste(here(), "/IPEDS/IPEDS_2017-18_Final/HD2017.xlsx", sep=""))
ic = readxl::read_xlsx(paste(here(), "/IPEDS/IPEDS_2017-18_Final/IC2017.xlsx", sep=""))
icay= readxl::read_xlsx(paste(here(), "/IPEDS/IPEDS_2017-18_Final/IC2017_AY.xlsx", sep=""))
mdat<- left_join(hd, ic, by ="UNITID")
mdat<-left_join(mdat, icay, by = "UNITID")
mdat<-mdat%>%
filter(CYACTIVE==1, HDEGOFR1>0, OPENADMP>0)%>%
select(UNITID, SECTOR, ICLEVEL, HLOFFER, GROFFER, HDEGOFR1, HBCU, LOCALE, INSTSIZE, OPENADMP)%>%
filter(complete.cases(.))
names(mdat)<- tolower(names(mdat))
mat <- model.matrix(~factor(sector)+factor(iclevel)+factor(hloffer)+factor(groffer)+factor(hdegofr1)+factor(hbcu)+factor(locale)+factor(instsize)+factor(openadmp)-1, data=mdat)
pcs <- prcomp(mat, retx=T, scale. = T, center = T)
ss <- NA
for (i in 1:10){
ss[i]<- kmeans(mat, centers = i, nstart=20)$withinss
}
plot(ss, type = "l")
plot(ss, type = "l")
out<- kmeans(mat, centers = 3, nstart=20)
out$centers
mdat$cluster <- out$cluster
library(ggplot2)
mdat%>%
group_by(cluster, sector, .drop=F )%>%
summarise(n = n()) %>%
mutate(freq = n / sum(n))%>%
ggplot()+
geom_bar(aes(x=cluster, y=freq, group=sector, fill=factor(sector) ),position="dodge", stat="identity")
mdat%>%
group_by(cluster, hdegofr1, .drop=F )%>%
summarise(n = n()) %>%
mutate(freq = n / sum(n))%>%
ggplot()+
geom_bar(aes(x=cluster, y=freq, group=sector, fill=factor(sector) ),position="dodge", stat="identity")
mdat%>%
group_by(cluster, hdegofr1, .drop=F )%>%
summarise(n = n()) %>%
mutate(freq = n / sum(n))%>%
ggplot()+
geom_bar(aes(x=cluster, y=freq, group=hdegofr1, fill=factor(hdegofr1) ),position="dodge", stat="identity")
knitr::opts_chunk$set(echo = TRUE)
t1<-data.frame(Day = c(rep("Tuesday", 7), rep("Wednesday", 7)),
topic = c("Introduction/What is R?",
"Installing R and Rstudio on your computer",
"Introduction to Rstudio",
"Break",
"Reading common files into R",
"Using R to summarize data",
"Q&A",
"Q&A",
"Basic ggplot",
"Break",
"Basic dplyr",
"R file types",
"Common packages",
"Q&A"))
knitr::kable(t1, caption = "Agenda", align = "c", format="html")
t1<-data.frame(Day = c(rep("Tuesday", 7), rep("Wednesday", 7)),
topic = c("Introduction/What is R?",
"Installing R and Rstudio on your computer",
"Introduction to Rstudio",
"Break",
"Reading common files into R",
"Using R to summarize data",
"Q&A",
"Q&A",
"Basic ggplot",
"Break",
"Basic dplyr",
"R file types",
"Common packages",
"Q&A"))
knitr::kable(t1, caption = "Agenda", align = "c", format="html")
#| label: tbl-agenda1
#| echo: true
#| tbl-cap: "Agenda for boot camp"
t1<-data.frame(Day = c(rep("Tuesday", 7), rep("Wednesday", 7)),
topic = c("Introduction/What is R?",
"Installing R and Rstudio on your computer",
"Introduction to Rstudio",
"Break",
"Reading common files into R",
"Using R to summarize data",
"Q&A",
"Q&A",
"Basic ggplot",
"Break",
"Basic dplyr",
"R file types",
"Common packages",
"Q&A"))
knitr::kable(t1, caption = "Agenda", align = "c", format="html")
#| label: tbl-agenda1
#| echo: true
#| tbl-cap: "Agenda for boot camp"
t1<-data.frame(Day = c(rep("Tuesday", 7), rep("Wednesday", 7)),
topic = c("Introduction/What is R?",
"Installing R and Rstudio on your computer",
"Introduction to Rstudio",
"Break",
"Reading common files into R",
"Using R to summarize data",
"Q&A",
"Q&A",
"Basic ggplot",
"Break",
"Basic dplyr",
"R file types",
"Common packages",
"Q&A"))
knitr::kable(t1, caption = "Agenda", align = "c", format="html")
#|
prb = readr::read_csv(url("https://raw.githubusercontent.com/coreysparks/r_courses/master/2018_WPDS_Data_Table_FINAL.csv"))
#| message: false
prb = readr::read_csv(url("https://raw.githubusercontent.com/coreysparks/r_courses/master/2018_WPDS_Data_Table_FINAL.csv"))
head(prb)
#| echo: false
#| label: tbl-rawdata
#| tbl-cap: "Penguin measurement data"
knitr::kable(head(prb))
#| message: false
prb = readr::read_csv(url("https://raw.githubusercontent.com/coreysparks/r_courses/master/2018_WPDS_Data_Table_FINAL.csv"))
#| eval: false
head(prb)
#| eval: false
haven::read_spss()
#| eval: false
haven::read_spss()
prb$country
head(prb$country)
head(prb[, "country"])
prb[["country"]]
names(prb)
summary(prb$pctwomcontra_mod)
skimr::skim(prb)
psych::describe(prb, fast = F)
table(prb$continent)
#| label: tbl-agenda1
#| echo: false
#| tbl-cap: "Agenda for boot camp"
t1<-data.frame(Day = c(rep("Day 1", 7),"---", rep("Day 2", 7)),
topic = c("Introduction/What is R?",
"Installing R and Rstudio on your computer",
"Introduction to Rstudio",
"Break",
"Reading common files into R",
"Using R to summarize data",
"Q&A",
"   ",
"Welcome/Questions",
"Basic ggplot",
"Break",
"Basic dplyr",
"R file types",
"Common packages",
"Q&A"))
knitr::kable(t1, align = "c")
#| message: false
prb = readr::read_csv(url("https://raw.githubusercontent.com/coreysparks/r_courses/master/2018_WPDS_Data_Table_FINAL.csv"))
#| echo: false
#| label: tbl-rawdata
#| tbl-cap: "Penguin measurement data"
knitr::kable(head(prb))
names(prb)
head(prb$country)
head(prb[, "country"])
summary(prb$region)
summary(as.factor(prb$continent))
summary(prb$pctwomcontra_mod)
psych::describe(prb, fast = F )
skimr::skim(prb)
table(prb$continent)
mean(prb$tfr)
mean(prb$tfr, na.rm = T)
median(prb$tfr, na.rm = T)
fivenum(prb$tfr)
summary(prb$tfr)
x<- rnorm(1000)
x
hist(x)
library(readr)
prball <- read_csv("C:/Users/ozd504/Github/data/prball.csv")
View(prball)
#| message: false
prb = readr::read_csv(url("https://raw.githubusercontent.com/coreysparks/r_courses/master/2018_WPDS_Data_Table_FINAL.csv"))
View(prb)
#| eval: false
head(prb, n=20)
table(x)
table(prb$continent, prb$e0male>60)
mean(prb$tfr)
mean(prb$gnigdp)
summary(prb$gnigdp)
mean(prb$gnigdp, na.rm = TRUE)
